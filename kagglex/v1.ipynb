{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54273 entries, 0 to 54272\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            54273 non-null  int64 \n",
      " 1   brand         54273 non-null  object\n",
      " 2   model         54273 non-null  object\n",
      " 3   model_year    54273 non-null  int64 \n",
      " 4   milage        54273 non-null  int64 \n",
      " 5   fuel_type     54273 non-null  object\n",
      " 6   engine        54273 non-null  object\n",
      " 7   transmission  54273 non-null  object\n",
      " 8   ext_col       54273 non-null  object\n",
      " 9   int_col       54273 non-null  object\n",
      " 10  accident      54273 non-null  object\n",
      " 11  clean_title   54273 non-null  object\n",
      " 12  price         54273 non-null  int64 \n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# Load the data into AutoGluon\n",
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "# Train the model\n",
    "label = \"price\"\n",
    "metric = 'rmse'  # specifies which metric to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240610_011137\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240610_011137/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 870 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2730 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2730s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240610_011137\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   aarch64\n",
      "Platform Version:   #57-Ubuntu SMP Wed Jan 24 18:31:24 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       19.90 GB / 23.43 GB (84.9%)\n",
      "Disk Space Avail:   130.75 GB / 193.63 GB (67.5%)\n",
      "===================================================\n",
      "Train Data Rows:    54273\n",
      "Train Data Columns: 12\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20397.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 33.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tFitting RenameFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['engine']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 113\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['clean_title']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['id', 'model_year', 'milage']\n",
      "\t\t('object', [])       : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('object', ['text']) : 1 | ['engine']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['engine']\n",
      "\t\t('int', [])                         :  3 | ['id', 'model_year', 'milage']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  1 | ['accident']\n",
      "\t\t('int', ['text_ngram'])             : 59 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n",
      "\t\t('object', ['text'])                :  1 | ['engine_raw_text']\n",
      "\t11.7s = Fit runtime\n",
      "\t11 features in original data used to generate 82 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.75 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.77s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1811.7s of the 2718.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.49%)\n",
      "\t-68595.0783\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.38s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1804.38s of the 2710.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
      "\t-68264.3737\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1796.49s of the 2703.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
      "\t-68281.8807\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.36s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1739.87s of the 2646.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.70%)\n",
      "\t-69036.8897\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.2s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1695.54s of the 2602.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
      "\t-68769.8818\t = Validation score   (-root_mean_squared_error)\n",
      "\t508.47s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit_BAG_L1 ... Training model for up to 1185.09s of the 2091.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
      "\tWarning: Exception caused VowpalWabbit_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1821425, ip=10.0.0.179)\n",
      "ModuleNotFoundError: No module named 'vowpalwabbit'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=1821425, ip=10.0.0.179)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/tabular/models/vowpalwabbit/vowpalwabbit_model.py\", line 68, in _fit\n",
      "    try_import_vowpalwabbit()\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/common/utils/try_import.py\", line 181, in try_import_vowpalwabbit\n",
      "    raise ImportError(\"`import vowpalwabbit` failed.\\n\" \"A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\")\n",
      "ImportError: `import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1182.67s of the 2089.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.72%)\n",
      "2024-06-10 01:36:53,935\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-10 01:36:53,937\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-10 01:36:53,938\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-69068.3684\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.58s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: MultiModalPredictor_BAG_L1 ... Training model for up to 1173.09s of the 2079.62s of remaining time.\n",
      "\tWarning: Exception caused MultiModalPredictor_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/ubuntu/Desktop/kaggle/.venv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit StackerEnsembleModel. Consider using a machine with more GPUs.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 2075.86s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.273, 'CatBoost_BAG_L1': 0.273, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.091, 'NeuralNetTorch_BAG_L1': 0.091, 'LightGBMLarge_BAG_L1': 0.091}\n",
      "\t-67946.3842\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 6 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2075.78s of the 2075.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.53%)\n",
      "\t-68573.9068\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2067.65s of the 2067.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.54%)\n",
      "\t-68078.6797\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.92s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2059.73s of the 2059.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
      "\t-67939.6042\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.34s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2012.19s of the 2012.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.77%)\n",
      "\t-68551.2635\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.51s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1977.56s of the 1977.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t-68341.9571\t = Validation score   (-root_mean_squared_error)\n",
      "\t312.76s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1662.82s of the 1662.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
      "\t-68926.7096\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.67s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1652.03s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.417, 'XGBoost_BAG_L2': 0.167, 'XGBoost_BAG_L1': 0.125, 'LightGBMXT_BAG_L1': 0.083, 'LightGBMXT_BAG_L2': 0.083, 'LightGBMLarge_BAG_L2': 0.083, 'NeuralNetTorch_BAG_L2': 0.042}\n",
      "\t-67819.8043\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1078.15s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240610_011137\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0xffff67bd9ed0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=metric, problem_type=\"regression\")\n",
    "\n",
    "predictor.fit(train_data, presets=\"best_quality\", hyperparameters=\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-54889.999376</td>\n",
       "      <td>-69036.889694</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.791878</td>\n",
       "      <td>0.375772</td>\n",
       "      <td>42.204319</td>\n",
       "      <td>2.791878</td>\n",
       "      <td>0.375772</td>\n",
       "      <td>42.204319</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-55326.453606</td>\n",
       "      <td>-69068.368390</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.950756</td>\n",
       "      <td>0.391347</td>\n",
       "      <td>7.579764</td>\n",
       "      <td>0.950756</td>\n",
       "      <td>0.391347</td>\n",
       "      <td>7.579764</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-61940.927334</td>\n",
       "      <td>-67946.384243</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>10.842878</td>\n",
       "      <td>2.486585</td>\n",
       "      <td>623.689080</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.059786</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-62541.932905</td>\n",
       "      <td>-68595.078322</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.775455</td>\n",
       "      <td>0.224020</td>\n",
       "      <td>5.379952</td>\n",
       "      <td>0.775455</td>\n",
       "      <td>0.224020</td>\n",
       "      <td>5.379952</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-62965.561740</td>\n",
       "      <td>-67819.804303</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>20.248133</td>\n",
       "      <td>4.846286</td>\n",
       "      <td>1028.949069</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.107913</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-63443.431533</td>\n",
       "      <td>-68926.709607</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.682534</td>\n",
       "      <td>2.957088</td>\n",
       "      <td>632.304056</td>\n",
       "      <td>0.844658</td>\n",
       "      <td>0.471621</td>\n",
       "      <td>8.674762</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-63884.714506</td>\n",
       "      <td>-68551.263499</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>13.436863</td>\n",
       "      <td>2.815963</td>\n",
       "      <td>656.141935</td>\n",
       "      <td>2.598987</td>\n",
       "      <td>0.330497</td>\n",
       "      <td>32.512641</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-64505.590951</td>\n",
       "      <td>-67939.604156</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.298496</td>\n",
       "      <td>2.790843</td>\n",
       "      <td>668.969912</td>\n",
       "      <td>0.460620</td>\n",
       "      <td>0.305377</td>\n",
       "      <td>45.340619</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-64718.284220</td>\n",
       "      <td>-68573.906849</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.366619</td>\n",
       "      <td>2.699035</td>\n",
       "      <td>629.820262</td>\n",
       "      <td>0.528743</td>\n",
       "      <td>0.213569</td>\n",
       "      <td>6.190969</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-64915.385656</td>\n",
       "      <td>-68264.373686</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>1.054762</td>\n",
       "      <td>0.433196</td>\n",
       "      <td>5.628837</td>\n",
       "      <td>1.054762</td>\n",
       "      <td>0.433196</td>\n",
       "      <td>5.628837</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-65457.927463</td>\n",
       "      <td>-68078.679673</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>11.459377</td>\n",
       "      <td>2.911531</td>\n",
       "      <td>629.548772</td>\n",
       "      <td>0.621501</td>\n",
       "      <td>0.426064</td>\n",
       "      <td>5.919478</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-65829.549621</td>\n",
       "      <td>-68281.880727</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.563707</td>\n",
       "      <td>0.334202</td>\n",
       "      <td>54.364482</td>\n",
       "      <td>0.563707</td>\n",
       "      <td>0.334202</td>\n",
       "      <td>54.364482</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-66750.111806</td>\n",
       "      <td>-68341.957119</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>15.716710</td>\n",
       "      <td>3.311211</td>\n",
       "      <td>936.393656</td>\n",
       "      <td>4.878834</td>\n",
       "      <td>0.825744</td>\n",
       "      <td>312.764362</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-67783.208259</td>\n",
       "      <td>-68769.881756</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>4.701317</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>508.471939</td>\n",
       "      <td>4.701317</td>\n",
       "      <td>0.726930</td>\n",
       "      <td>508.471939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model    score_test     score_val  \\\n",
       "0          XGBoost_BAG_L1 -54889.999376 -69036.889694   \n",
       "1    LightGBMLarge_BAG_L1 -55326.453606 -69068.368390   \n",
       "2     WeightedEnsemble_L2 -61940.927334 -67946.384243   \n",
       "3         LightGBM_BAG_L1 -62541.932905 -68595.078322   \n",
       "4     WeightedEnsemble_L3 -62965.561740 -67819.804303   \n",
       "5    LightGBMLarge_BAG_L2 -63443.431533 -68926.709607   \n",
       "6          XGBoost_BAG_L2 -63884.714506 -68551.263499   \n",
       "7         CatBoost_BAG_L2 -64505.590951 -67939.604156   \n",
       "8         LightGBM_BAG_L2 -64718.284220 -68573.906849   \n",
       "9       LightGBMXT_BAG_L1 -64915.385656 -68264.373686   \n",
       "10      LightGBMXT_BAG_L2 -65457.927463 -68078.679673   \n",
       "11        CatBoost_BAG_L1 -65829.549621 -68281.880727   \n",
       "12  NeuralNetTorch_BAG_L2 -66750.111806 -68341.957119   \n",
       "13  NeuralNetTorch_BAG_L1 -67783.208259 -68769.881756   \n",
       "\n",
       "                eval_metric  pred_time_test  pred_time_val     fit_time  \\\n",
       "0   root_mean_squared_error        2.791878       0.375772    42.204319   \n",
       "1   root_mean_squared_error        0.950756       0.391347     7.579764   \n",
       "2   root_mean_squared_error       10.842878       2.486585   623.689080   \n",
       "3   root_mean_squared_error        0.775455       0.224020     5.379952   \n",
       "4   root_mean_squared_error       20.248133       4.846286  1028.949069   \n",
       "5   root_mean_squared_error       11.682534       2.957088   632.304056   \n",
       "6   root_mean_squared_error       13.436863       2.815963   656.141935   \n",
       "7   root_mean_squared_error       11.298496       2.790843   668.969912   \n",
       "8   root_mean_squared_error       11.366619       2.699035   629.820262   \n",
       "9   root_mean_squared_error        1.054762       0.433196     5.628837   \n",
       "10  root_mean_squared_error       11.459377       2.911531   629.548772   \n",
       "11  root_mean_squared_error        0.563707       0.334202    54.364482   \n",
       "12  root_mean_squared_error       15.716710       3.311211   936.393656   \n",
       "13  root_mean_squared_error        4.701317       0.726930   508.471939   \n",
       "\n",
       "    pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0                  2.791878                0.375772          42.204319   \n",
       "1                  0.950756                0.391347           7.579764   \n",
       "2                  0.005002                0.001118           0.059786   \n",
       "3                  0.775455                0.224020           5.379952   \n",
       "4                  0.005657                0.001516           0.107913   \n",
       "5                  0.844658                0.471621           8.674762   \n",
       "6                  2.598987                0.330497          32.512641   \n",
       "7                  0.460620                0.305377          45.340619   \n",
       "8                  0.528743                0.213569           6.190969   \n",
       "9                  1.054762                0.433196           5.628837   \n",
       "10                 0.621501                0.426064           5.919478   \n",
       "11                 0.563707                0.334202          54.364482   \n",
       "12                 4.878834                0.825744         312.764362   \n",
       "13                 4.701317                0.726930         508.471939   \n",
       "\n",
       "    stack_level  can_infer  fit_order  \n",
       "0             1       True          4  \n",
       "1             1       True          6  \n",
       "2             2       True          7  \n",
       "3             1       True          1  \n",
       "4             3       True         14  \n",
       "5             2       True         13  \n",
       "6             2       True         11  \n",
       "7             2       True         10  \n",
       "8             2       True          8  \n",
       "9             1       True          2  \n",
       "10            2       True          9  \n",
       "11            1       True          3  \n",
       "12            2       True         12  \n",
       "13            1       True          5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_sample = pd.read_csv('./data/sample_submission.csv')\n",
    "op_sample['price'] = predictions\n",
    "op_sample.to_csv('submission_v1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
