{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the csv file\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1117957 entries, 0 to 1117956\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count    Dtype  \n",
      "---  ------                           --------------    -----  \n",
      " 0   id                               1117957 non-null  int64  \n",
      " 1   MonsoonIntensity                 1117957 non-null  int64  \n",
      " 2   TopographyDrainage               1117957 non-null  int64  \n",
      " 3   RiverManagement                  1117957 non-null  int64  \n",
      " 4   Deforestation                    1117957 non-null  int64  \n",
      " 5   Urbanization                     1117957 non-null  int64  \n",
      " 6   ClimateChange                    1117957 non-null  int64  \n",
      " 7   DamsQuality                      1117957 non-null  int64  \n",
      " 8   Siltation                        1117957 non-null  int64  \n",
      " 9   AgriculturalPractices            1117957 non-null  int64  \n",
      " 10  Encroachments                    1117957 non-null  int64  \n",
      " 11  IneffectiveDisasterPreparedness  1117957 non-null  int64  \n",
      " 12  DrainageSystems                  1117957 non-null  int64  \n",
      " 13  CoastalVulnerability             1117957 non-null  int64  \n",
      " 14  Landslides                       1117957 non-null  int64  \n",
      " 15  Watersheds                       1117957 non-null  int64  \n",
      " 16  DeterioratingInfrastructure      1117957 non-null  int64  \n",
      " 17  PopulationScore                  1117957 non-null  int64  \n",
      " 18  WetlandLoss                      1117957 non-null  int64  \n",
      " 19  InadequatePlanning               1117957 non-null  int64  \n",
      " 20  PoliticalFactors                 1117957 non-null  int64  \n",
      " 21  FloodProbability                 1117957 non-null  float64\n",
      "dtypes: float64(1), int64(21)\n",
      "memory usage: 187.6 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# Load the data into AutoGluon\n",
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "# Train the model\n",
    "label = \"FloodProbability\"\n",
    "metric = 'r2'  # specifies which metric to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240527_122131\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240527_122131/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 165 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 435 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 435s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240527_122131\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   aarch64\n",
      "Platform Version:   #57-Ubuntu SMP Wed Jan 24 18:31:24 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       18.80 GB / 23.43 GB (80.3%)\n",
      "Disk Space Avail:   143.56 GB / 193.63 GB (74.1%)\n",
      "===================================================\n",
      "Train Data Rows:    1117957\n",
      "Train Data Columns: 21\n",
      "Label Column:       FloodProbability\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19199.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 179.12 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 21 | ['id', 'MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 21 | ['id', 'MonsoonIntensity', 'TopographyDrainage', 'RiverManagement', 'Deforestation', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t21 features in original data used to generate 21 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 179.12 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'VW': {},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 8 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 288.54s of the 432.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=5.87%)\n",
      "\t0.8405\t = Validation score   (r2)\n",
      "\t249.43s\t = Training   runtime\n",
      "\t107.48s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 22.93s of the 167.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=5.87%)\n",
      "\t0.3612\t = Validation score   (r2)\n",
      "\t22.1s\t = Training   runtime\n",
      "\t3.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 142.45s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.8405\t = Validation score   (r2)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 6 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 141.56s of the 141.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=6.21%)\n",
      "\t0.8494\t = Validation score   (r2)\n",
      "\t80.26s\t = Training   runtime\n",
      "\t11.26s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 55.65s of the 55.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=6.20%)\n",
      "\t0.8474\t = Validation score   (r2)\n",
      "\t49.64s\t = Training   runtime\n",
      "\t10.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2.15s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.562, 'LightGBMXT_BAG_L2': 0.375, 'LightGBM_BAG_L1': 0.062}\n",
      "\t0.851\t = Validation score   (r2)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 434.46s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240527_122131\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0xffff3f1266b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=metric, problem_type=\"regression\")\n",
    "\n",
    "predictor.fit(train_data, time_limit=600, presets=\"best_quality\", hyperparameters=\"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.861886</td>\n",
       "      <td>0.849377</td>\n",
       "      <td>r2</td>\n",
       "      <td>264.829142</td>\n",
       "      <td>122.128572</td>\n",
       "      <td>351.781819</td>\n",
       "      <td>24.534845</td>\n",
       "      <td>11.263553</td>\n",
       "      <td>80.255419</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.861539</td>\n",
       "      <td>0.851022</td>\n",
       "      <td>r2</td>\n",
       "      <td>286.348881</td>\n",
       "      <td>132.780040</td>\n",
       "      <td>402.693856</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0.018706</td>\n",
       "      <td>1.275076</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.857992</td>\n",
       "      <td>0.847444</td>\n",
       "      <td>r2</td>\n",
       "      <td>261.797906</td>\n",
       "      <td>121.497781</td>\n",
       "      <td>321.163361</td>\n",
       "      <td>21.503610</td>\n",
       "      <td>10.632761</td>\n",
       "      <td>49.636961</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>0.840533</td>\n",
       "      <td>r2</td>\n",
       "      <td>233.061303</td>\n",
       "      <td>107.478712</td>\n",
       "      <td>249.429587</td>\n",
       "      <td>233.061303</td>\n",
       "      <td>107.478712</td>\n",
       "      <td>249.429587</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>0.840533</td>\n",
       "      <td>r2</td>\n",
       "      <td>233.068677</td>\n",
       "      <td>107.495094</td>\n",
       "      <td>250.256340</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.826753</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.365718</td>\n",
       "      <td>0.361183</td>\n",
       "      <td>r2</td>\n",
       "      <td>7.232993</td>\n",
       "      <td>3.386307</td>\n",
       "      <td>22.096812</td>\n",
       "      <td>7.232993</td>\n",
       "      <td>3.386307</td>\n",
       "      <td>22.096812</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0      LightGBM_BAG_L2    0.861886   0.849377          r2      264.829142   \n",
       "1  WeightedEnsemble_L3    0.861539   0.851022          r2      286.348881   \n",
       "2    LightGBMXT_BAG_L2    0.857992   0.847444          r2      261.797906   \n",
       "3      LightGBM_BAG_L1    0.849734   0.840533          r2      233.061303   \n",
       "4  WeightedEnsemble_L2    0.849734   0.840533          r2      233.068677   \n",
       "5    LightGBMXT_BAG_L1    0.365718   0.361183          r2        7.232993   \n",
       "\n",
       "   pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0     122.128572  351.781819                24.534845               11.263553   \n",
       "1     132.780040  402.693856                 0.016130                0.018706   \n",
       "2     121.497781  321.163361                21.503610               10.632761   \n",
       "3     107.478712  249.429587               233.061303              107.478712   \n",
       "4     107.495094  250.256340                 0.007374                0.016382   \n",
       "5       3.386307   22.096812                 7.232993                3.386307   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          80.255419            2       True          4  \n",
       "1           1.275076            3       True          6  \n",
       "2          49.636961            2       True          5  \n",
       "3         249.429587            1       True          1  \n",
       "4           0.826753            2       True          3  \n",
       "5          22.096812            1       True          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_sample = pd.read_csv('data/sample_submission.csv')\n",
    "op_sample['FloodProbability'] = predictions\n",
    "op_sample.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
